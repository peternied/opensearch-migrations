apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: kafka-setup-better
spec:
  entrypoint: setup-kafka-with-users
  serviceAccountName: argo-workflow-executor

  templates:
    - name: setup-kafka-with-users
      inputs:
        parameters:
          - name: kafka-name
      outputs:
        parameters:
          - name: kafka-name
            valueFrom:
              expression: "inputs.parameters['kafka-name']"
          - name: bootstrapServers
            valueFrom:
              expression: "tasks.deployCluster.outputs.parameters['bootstrap-servers']"
          - name: clusterCaPem
            valueFrom:
              expression: "tasks.exportClusterCa.outputs.parameters['cluster-ca-pem']"
          - name: captureProxyPropertiesSecret
            valueFrom:
              expression: "tasks.createClientBundles.outputs.parameters['secret-name'][0]"
          - name: replayerPropertiesSecret
            valueFrom:
              expression: "tasks.createClientBundles.outputs.parameters['secret-name'][1]"
          - name: consolePropertiesSecret
            valueFrom:
              expression: "tasks.createClientBundles.outputs.parameters['secret-name'][2]"
      dag:
        tasks:
          - name: deployCluster
            template: cluster-deploy
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"

          - name: exportClusterCa
            dependencies: [deployCluster]
            template: export-cluster-ca
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"

          - name: createClientBundles
            dependencies: [deployCluster, exportClusterCa]
            template: create-kafka-client-bundle
            withItems:
              - { role: "capture-proxy" }
              - { role: "replayer" }
              - { role: "console" }
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"
                - name: role
                  value: "{{item.role}}"
                - name: bootstrapServers
                  value: "{{tasks.deployCluster.outputs.parameters.bootstrap-servers}}"
                - name: caSecretName
                  value: "{{inputs.parameters.kafka-name}}-cluster-ca-cert"

    - name: cluster-deploy
      inputs:
        parameters:
          - name: kafka-name
      outputs:
        parameters:
          - name: bootstrap-servers
            valueFrom:
              expression: "tasks.kafka.outputs.parameters['brokers']"
      dag:
        tasks:
          - name: nodepool
            template: deploy-kafka-node-pool
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"
          - name: kafka
            dependencies: [nodepool]
            template: deploy-kafka-cluster-kraft
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"

    - name: deploy-kafka-node-pool
      inputs:
        parameters:
          - name: kafka-name
      resource:
        action: apply
        setOwnerReference: true
        manifest: |
          apiVersion: kafka.strimzi.io/v1beta2
          kind: KafkaNodePool
          metadata:
            name: dual-role
            labels:
              strimzi.io/cluster: {{inputs.parameters.kafka-name}}
          spec:
            replicas: 1
            roles:
              - controller
              - broker
            storage:
              type: jbod
              volumes:
                - id: 0
                  type: persistent-claim
                  size: 5Gi
                  deleteClaim: false
                  kraftMetadata: shared

    - name: deploy-kafka-cluster-kraft
      inputs:
        parameters:
          - name: kafka-name
      outputs:
        parameters:
          - name: brokers
            valueFrom:
              jsonPath: "{.status.listeners[].bootstrapServers}"
      resource:
        action: apply
        setOwnerReference: true
        successCondition: status.listeners
        manifest: |
          apiVersion: kafka.strimzi.io/v1beta2
          kind: Kafka
          metadata:
            name: {{inputs.parameters.kafka-name}}
            annotations:
              strimzi.io/node-pools: enabled
              strimzi.io/kraft: enabled
          spec:
            kafka:
              version: 3.9.0
              metadataVersion: 3.9-IV0
              readinessProbe:
                initialDelaySeconds: 1
                periodSeconds: 2
                timeoutSeconds: 2
                failureThreshold: 1
              livenessProbe:
                initialDelaySeconds: 1
                periodSeconds: 2
                timeoutSeconds: 2
                failureThreshold: 2
              listeners:
                - name: tls
                  port: 9093
                  type: internal
                  tls: true
                  authentication:
                    type: scram-sha-512
              authorization:
                type: simple
              config:
                auto.create.topics.enable: false
                offsets.topic.replication.factor: 1
                transaction.state.log.replication.factor: 1
                transaction.state.log.min.isr: 1
                default.replication.factor: 1
                min.insync.replicas: 1
            entityOperator:
                topicOperator: {}
                userOperator: {}

    - name: export-cluster-ca
      inputs:
        parameters:
          - name: kafka-name
      outputs:
        parameters:
          - name: cluster-ca-pem
            valueFrom:
              path: /tmp/ca.crt
      script:
        image: bitnamisecure/kubectl:latest
        command: [bash, -lc]
        source: |
          set -euo pipefail
          SECRET="{{inputs.parameters.kafka-name}}-cluster-ca-cert"
          # Extract PEM (base64-decoded) into a file for Argo to capture as a parameter.
          kubectl get secret "${SECRET}" -o jsonpath='{.data.ca\.crt}' \
            | base64 -d > /tmp/ca.crt

    - name: create-kafka-client-bundle
      inputs:
        parameters:
          - name: kafka-name
          - name: role
          - name: bootstrapServers
          - name: caSecretName
          - name: targetNamespace
            value: "{{workflow.namespace}}"
          - name: mountPath
            value: "/opt/kafka-config"
      outputs:
        parameters:
          - name: secret-name
            valueFrom:
              path: /tmp/secret_name
      script:
        image: bitnamisecure/kubectl:latest
        command: ["/bin/bash","-euo","pipefail","-c"]
        source: |
          set -euo pipefail
          KAFKA_NAME="{{inputs.parameters.kafka-name}}"
          ROLE="{{inputs.parameters.role}}"
          USERNAME="${KAFKA_NAME}-${ROLE}"
          CA_SECRET="{{inputs.parameters.caSecretName}}"
          NS="{{inputs.parameters.targetNamespace}}"
          MOUNT="{{inputs.parameters.mountPath}}"
          WORK=/work
          mkdir -p "$WORK"

          echo "${USERNAME}-properties" > /tmp/secret_name

          # Create the KafkaUser with Strimzi
          cat <<EOF | kubectl apply -f -
          apiVersion: kafka.strimzi.io/v1beta2
          kind: KafkaUser
          metadata:
            name: "${USERNAME}"
            labels:
              strimzi.io/cluster: "${KAFKA_NAME}"
          spec:
            authentication:
              type: scram-sha-512
            authorization:
              type: simple
              acls:
                - operation: Describe
                  resource:
                    type: topic
                    name: '*'
                    patternType: literal
                - operation: Describe
                  resource:
                    type: group
                    name: '*'
                    patternType: literal
          EOF

          # Wait for Strimzi to create the user Secret
          #    Secret keys include: username, password, sasl.jaas.config, mechanism
          for i in {1..60}; do
            if kubectl get secret "${USERNAME}" >/dev/null 2>&1; then break; fi
            sleep 2
          done
          kubectl get secret "${USERNAME}" -o jsonpath='{.data.sasl\.jaas\.config}' | base64 -d > "$WORK/sasl.jaas.config"

          # Grab truststore (PKCS12) + password from the CA secret
          kubectl get secret "${CA_SECRET}" -o jsonpath='{.data.ca\.p12}' | base64 -d > "$WORK/ca.p12"
          kubectl get secret "${CA_SECRET}" -o jsonpath='{.data.ca\.password}' | base64 -d > "$WORK/ca.password"
          TRUSTPASS="$(cat "$WORK/ca.password")"

          # Render kafka.properties
          cat > "$WORK/kafka.properties" <<EOF
          security.protocol=SASL_SSL
          sasl.mechanism=SCRAM-SHA-512
          sasl.jaas.config=$(cat "$WORK/sasl.jaas.config")
          ssl.truststore.type=PKCS12
          ssl.truststore.location={{inputs.parameters.mountPath}}/ca.p12
          ssl.truststore.password=${TRUSTPASS}
          bootstrap.servers={{inputs.parameters.bootstrapServers}}
          client.id=${USERNAME}
          EOF

          # 5) Secret the bundle for mounting by apps
          kubectl -n "$NS" create secret generic "${USERNAME}-properties" \
            --from-file=kafka.properties="$WORK/kafka.properties" \
            --from-file=ca.p12="$WORK/ca.p12" \
            --from-file=ca.password="$WORK/ca.password" \
            --dry-run=client -o yaml | kubectl apply -f -
      podSpecPatch: |
        {
          "volumes": [
            { "name": "work", "emptyDir": {} }
          ],
          "containers": [
            {
              "name": "main",
              "volumeMounts": [
                {"name": "work", "mountPath": "/work"}
              ]
            }
          ],
          "serviceAccountName": "argo-workflow-executor"
        }
