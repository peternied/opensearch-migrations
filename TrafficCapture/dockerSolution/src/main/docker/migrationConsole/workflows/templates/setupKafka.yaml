apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: kafka-setup-better
spec:
  entrypoint: cluster-deploy
  serviceAccountName: argo-workflow-executor

  templates:
    - name: setup-kafka-with-users
      inputs:
        parameters:
          - name: kafka-name
      outputs:
        parameters:
          - name: kafka-name
            valueFrom:
              expression: "inputs.parameters['kafka-name']"
          - name: bootstrapServers
            valueFrom:
              expression: tasks.deployCluster.outputs.parameters.bootstrap-servers
          - name: clusterCaPem
            valueFrom:
              expression: tasks.deployCluster.outputs.parameters.cluster-ca-pem
          - name: captureProxyPropertiesSecret
            valueFrom:
              expression: tasks.createCaptureProxyProperties.outputs.parameters.secretName
          - name: replayerPropertiesSecret
            valueFrom:
              expression: tasks.createReplayerProperties.outputs.parameters.secretName
          - name: consolePropertiesSecret
            valueFrom:
              expression: tasks.createConsoleProperties.outputs.parameters.secretName
      dag:
        tasks:
          - name: deployCluster
            template: cluster-deploy
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"
          - name: createUsers
            template: createrequiredusers
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"
            dependencies:
              - deployCluster
          - name: exportClusterCa
            template: export-cluster-ca
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"
            dependencies:
              - deployCluster
          - name: createCaptureProxyProperties
            template: create-kafka-properties-file
            arguments:
              parameters:
                - name: secretName
                  value: "{{inputs.parameters.kafka-name}}-capture-proxy-properties"
                - name: userSecretName
                  value: "{{tasks.createUsers.outputs.parameters.captureProxySecret}}"
                - name: username                                  # <-- ADD
                  value: "{{tasks.createUsers.outputs.parameters.captureProxyUsername}}"
                - name: caSecretName
                  value: "{{inputs.parameters.kafka-name}}-cluster-ca-cert"
                - name: bootstrapServers
                  value: "{{tasks.deployCluster.outputs.parameters.bootstrap-servers}}"
                - name: clientId
                  value: "{{inputs.parameters.kafka-name}}-capture-proxy"
            dependencies:
              - createUsers
          - name: createReplayerProperties
            template: create-kafka-properties-file
            arguments:
              parameters:
                - name: secretName
                  value: "{{inputs.parameters.kafka-name}}-replayer-properties"
                - name: userSecretName
                  value: "{{tasks.createUsers.outputs.parameters.replayerSecret}}"
                - name: username
                  value: "{{tasks.createUsers.outputs.parameters.replayerUsername}}"
                - name: caSecretName
                  value: "{{inputs.parameters.kafka-name}}-cluster-ca-cert"
                - name: bootstrapServers
                  value: "{{tasks.deployCluster.outputs.parameters.bootstrap-servers}}"
                - name: clientId
                  value: "{{inputs.parameters.kafka-name}}-replayer"
            dependencies:
              - createUsers
          - name: createConsoleProperties
            template: create-kafka-properties-file
            arguments:
              parameters:
                - name: secretName
                  value: "{{inputs.parameters.kafka-name}}-console-properties"
                - name: userSecretName
                  value: "{{tasks.createUsers.outputs.parameters.consoleSecret}}"
                - name: username
                  value: "{{tasks.createUsers.outputs.parameters.consoleUsername}}"
                - name: caSecretName
                  value: "{{inputs.parameters.kafka-name}}-cluster-ca-cert"
                - name: bootstrapServers
                  value: "{{tasks.deployCluster.outputs.parameters.bootstrap-servers}}"
                - name: clientId
                  value: "{{inputs.parameters.kafka-name}}-console"
            dependencies:
              - createUsers
    - name: cluster-deploy
      inputs:
        parameters:
          - name: kafka-name
      outputs:
        parameters:
          - name: kafka-name
            valueFrom:
              expression: "inputs.parameters['kafka-name']"
          - name: bootstrap-servers
            valueFrom:
              expression: >-
                tasks['deploy-kafka-cluster-kraft'].outputs.parameters['brokers']
          - name: cluster-ca-pem
            valueFrom:
              expression: >-
                tasks['export-cluster-ca'].outputs.parameters['cluster-ca-pem']
      dag:
        tasks:
          - name: deploy-kafka-node-pool
            template: deploy-kafka-node-pool
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"

          - name: deploy-kafka-cluster-kraft
            template: deploy-kafka-cluster-kraft
            dependencies: [deploy-kafka-node-pool]
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"

          - name: export-cluster-ca
            template: export-cluster-ca
            dependencies: [deploy-kafka-cluster-kraft]
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"

    - name: deploy-kafka-node-pool
      inputs:
        parameters:
          - name: kafka-name
      resource:
        action: apply
        setOwnerReference: true
        manifest: |
          apiVersion: kafka.strimzi.io/v1beta2
          kind: KafkaNodePool
          metadata:
            name: dual-role
            labels:
              strimzi.io/cluster: {{inputs.parameters.kafka-name}}
          spec:
            replicas: 1
            roles:
              - controller
              - broker
            storage:
              type: jbod
              volumes:
                - id: 0
                  type: persistent-claim
                  size: 5Gi
                  deleteClaim: false
                  kraftMetadata: shared

    - name: deploy-kafka-cluster-kraft
      inputs:
        parameters:
          - name: kafka-name
      outputs:
        parameters:
          - name: brokers
            valueFrom:
              jsonPath: "{.status.listeners[].bootstrapServers}"
      resource:
        action: apply
        setOwnerReference: true
        successCondition: status.listeners
        manifest: |
          apiVersion: kafka.strimzi.io/v1beta2
          kind: Kafka
          metadata:
            name: {{inputs.parameters.kafka-name}}
            annotations:
              strimzi.io/node-pools: enabled
              strimzi.io/kraft: enabled
          spec:
            kafka:
              version: 3.9.0
              metadataVersion: 3.9-IV0
              readinessProbe:
                initialDelaySeconds: 1
                periodSeconds: 2
                timeoutSeconds: 2
                failureThreshold: 1
              livenessProbe:
                initialDelaySeconds: 1
                periodSeconds: 2
                timeoutSeconds: 2
                failureThreshold: 2
              listeners:
                - name: tls
                  port: 9093
                  type: internal
                  tls: true
                  authentication:
                    type: scram-sha-512
              authorization:
                type: simple
              config:
                auto.create.topics.enable: false
                offsets.topic.replication.factor: 1
                transaction.state.log.replication.factor: 1
                transaction.state.log.min.isr: 1
                default.replication.factor: 1
                min.insync.replicas: 1
            entityOperator:
                topicOperator: {}
                userOperator: {}

    - name: export-cluster-ca
      inputs:
        parameters:
          - name: kafka-name
      outputs:
        parameters:
          - name: cluster-ca-pem
            valueFrom:
              path: /tmp/ca.crt
      script:
        image: bitnamisecure/kubectl:latest
        command: [bash, -lc]
        source: |
          set -euo pipefail
          SECRET="{{inputs.parameters.kafka-name}}-cluster-ca-cert"
          # Extract PEM (base64-decoded) into a file for Argo to capture as a parameter.
          kubectl get secret "${SECRET}" -o jsonpath='{.data.ca\.crt}' \
            | base64 -d > /tmp/ca.crt

    - name: create-kafka-topic
      inputs:
        parameters:
          - name: kafka-name
          - name: topic-name
          - name: topic-partitions
            value: ""
            description: "Number of partitions for the created topic"
          - name: default-topic-partitions
            value: "1"
            description: "Default number of partitions for the created topic, which will be applied when the topic-partitions is empty or nil."
          - name: topic-replicas
            value: ""
            description: "Number of replicas for the created topic"
          - name: default-topic-replicas
            value: "1"
            description: "Default number of replicas for the created topic, which will be applied when the topic-replicas is empty or nil."
      outputs:
        parameters:
          - name: topic-name
            valueFrom:
              jsonPath: "{.status.topicName}"
      resource:
        action: apply
        setOwnerReference: true
        successCondition: status.topicName
        manifest: |
          apiVersion: kafka.strimzi.io/v1beta2
          kind: KafkaTopic
          metadata:
            name: {{inputs.parameters.topic-name}}
            labels:
              strimzi.io/cluster: {{inputs.parameters.kafka-name}}
          spec:
            partitions: {{=let v=inputs.parameters['topic-partitions']; (v==nil || v=='') ? inputs.parameters['default-topic-partitions'] : v}}
            replicas:   {{=let v=inputs.parameters['topic-replicas'];   (v==nil || v=='') ? inputs.parameters['default-topic-replicas']   : v}}
            config:
              retention.ms: 604800000
              segment.bytes: 1073741824

    - name: create-kafka-user
      inputs:
        parameters:
          - name: kafka-name
          - name: userName
          - name: userType
      outputs:
        parameters:
          - name: username
            valueFrom:
              jsonPath: "{.status.username}"
          - name: secret
            valueFrom:
              jsonPath: "{.status.secret}"
      resource:
        action: apply
        manifest: |
          apiVersion: kafka.strimzi.io/v1beta2
          kind: KafkaUser
          metadata:
            name: '{{inputs.parameters.userName}}'
            labels:
              strimzi.io/cluster: '{{inputs.parameters.kafka-name}}'
          spec:
            authentication:
              type: scram-sha-512
            authorization:
              type: simple
              acls:
                - operation: Describe
                  resource:
                    type: topic
                    name: '*'
                    patternType: literal
                - operation: Describe
                  resource:
                    type: group
                    name: '*'
                    patternType: literal
        setOwnerReference: true
        successCondition: status.username

    - name: createrequiredusers
      inputs:
        parameters:
          - name: kafka-name
      outputs:
        parameters:
          - name: captureProxyUsername
            valueFrom:
              expression: tasks.createCaptureProxyUser.outputs.parameters.username
          - name: replayerUsername
            valueFrom:
              expression: tasks.createReplayerUser.outputs.parameters.username
          - name: consoleUsername
            valueFrom:
              expression: tasks.createConsoleUser.outputs.parameters.username
          - name: captureProxySecret
            valueFrom:
              expression: tasks.createCaptureProxyUser.outputs.parameters.secret
          - name: replayerSecret
            valueFrom:
              expression: tasks.createReplayerUser.outputs.parameters.secret
          - name: consoleSecret
            valueFrom:
              expression: tasks.createConsoleUser.outputs.parameters.secret
      dag:
        tasks:
          - name: createCaptureProxyUser
            template: create-kafka-user
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"
                - name: userName
                  value: "{{inputs.parameters.kafka-name}}-capture-proxy"
                - name: userType
                  value: "capture-proxy"
          - name: createReplayerUser
            template: create-kafka-user
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"
                - name: userName
                  value: "{{inputs.parameters.kafka-name}}-replayer"
                - name: userType
                  value: replayer
          - name: createConsoleUser
            template: create-kafka-user
            arguments:
              parameters:
                - name: kafka-name
                  value: "{{inputs.parameters.kafka-name}}"
                - name: userName
                  value: "{{inputs.parameters.kafka-name}}-console"
                - name: userType
                  value: console
    - name: create-kafka-properties-file
      inputs:
        parameters:
          - name: secretName
          - name: userSecretName
          - name: username
          - name: caSecretName
          - name: bootstrapServers
          - name: clientId
          - name: mountPath
            value: "/opt/kafka-config"
          - name: targetNamespace
            value: "{{workflow.namespace}}"
      outputs:
        parameters:
          - name: secretName
            valueFrom:
              path: /tmp/secret_name
      script:
        image: bitnamisecure/kubectl:latest
        command: ["/bin/bash","-euo","pipefail","-c"]
        env:
          - name: SASL_USERNAME
            value: "{{inputs.parameters.username}}"
          - name: SASL_PASSWORD
            valueFrom:
              secretKeyRef:
                name: "{{inputs.parameters.userSecretName}}"
                key: password
          - name: TRUSTPASS
            valueFrom:
              secretKeyRef:
                name: "{{inputs.parameters.caSecretName}}"
                key: ca.password
        source: |
          WORK=/work
          mkdir -p "$WORK"

          # Copy truststore from the mounted CA secret so we can package it into the new Secret
          cp /var/run/ca-secret/ca.p12 "$WORK/ca.p12"
          printf "%s" "$TRUSTPASS" > "$WORK/ca.password"

          # Render kafka.properties using ENV vars
          KAFKA_PROPERTIES_FILE="$WORK/kafka.properties"
          
          # Save secret name to output file
          echo "{{inputs.parameters.secretName}}" > /tmp/secret_name
          
          cat > "$KAFKA_PROPERTIES_FILE" <<-EOF
          security.protocol=SASL_SSL
          sasl.mechanism=SCRAM-SHA-512
          sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username='${SASL_USERNAME}' password='${SASL_PASSWORD}';
          ssl.truststore.type=PKCS12
          ssl.truststore.location={{inputs.parameters.mountPath}}/ca.p12
          ssl.truststore.password=${TRUSTPASS}
          bootstrap.servers={{inputs.parameters.bootstrapServers}}
          $( [[ -n "{{inputs.parameters.clientId}}" ]] && echo "client.id={{inputs.parameters.clientId}}" )
          EOF

          kubectl -n "{{inputs.parameters.targetNamespace}}" create secret generic "{{inputs.parameters.secretName}}" \
            --from-file=kafka.properties="$KAFKA_PROPERTIES_FILE" \
            --from-file=ca.p12="$WORK/ca.p12" \
            --from-file=ca.password="$WORK/ca.password" \
            --dry-run=client -o yaml | kubectl apply -f -
      podSpecPatch: |
        {
          "volumes": [
            {
              "name": "ca-secret",
              "secret": {
                "secretName": "{{inputs.parameters.caSecretName}}",
                "items": [
                  {"key": "ca.p12", "path": "ca.p12"}
                ]
              }
            },
            { "name": "work", "emptyDir": {} }
          ],
          "containers": [
            {
              "name": "main",
              "volumeMounts": [
                {"name": "ca-secret", "mountPath": "/var/run/ca-secret", "readOnly": true},
                {"name": "work", "mountPath": "/work"}
              ]
            }
          ],
          "serviceAccountName": "argo-workflow-executor"
        }
